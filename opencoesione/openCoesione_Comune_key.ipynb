{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reformat openCoesione dataset with Comune as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Runs with \"daf\" enviroment in repo\n",
    "\n",
    "%config Completer.use_jedi = False #fix TAB slowness with big frames\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import gc #garbage collector\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,12)\n",
    "\n",
    "columnsToDrop = {\n",
    "    'soggetti': ['INDIRIZZO_SOGG','SOGG_DESCR_RUOLO'],\n",
    "    'progetti':['OC_LINK'],\n",
    "    'localizzazioni':['INDIRIZZO_PROG'],\n",
    "    'pagamenti':[]}\n",
    "\n",
    "def load_and_stack_data(prefix):\n",
    "    fileList = glob.glob('./../pac_opencoesione/%s*.csv' % prefix)\n",
    "    \n",
    "    if prefix == 'progetti':\n",
    "        dtypesDict = pd.read_csv(\n",
    "            './openCoesione_dtypes.csv', index_col='Variabile', squeeze=True).to_dict()\n",
    "        dateCols = [name for name in dtypesDict.keys() if dtypesDict[name] == 'datetime64']\n",
    "        for name in dateCols: del dtypesDict[name]\n",
    "        frames = list(map(lambda f: pd.read_csv(\n",
    "            f, sep=';', dtype=dtypesDict, index_col=0, na_values=[' ', '  ']), fileList))\n",
    "        data = pd.concat(frames, axis=0)\n",
    "        data[dateCols] = data[dateCols].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True))\n",
    "        \n",
    "        # drop duplicates including index when checking\n",
    "        indexColName = data.index.name\n",
    "        data.reset_index(inplace=True)\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        data.set_index(indexColName, inplace=True)\n",
    "        \n",
    "        # clean remaining duplicate indexes by picking the row that has fewer N/A\n",
    "        bDuplicate = data.index.duplicated(keep=False)\n",
    "        if any(bDuplicate):\n",
    "            print('%i duplicate indexes found' % sum(bDuplicate))\n",
    "            duplRows = data[bDuplicate].copy()\n",
    "            duplRows['NumberNA'] = duplRows.isna().sum(axis=1)\n",
    "            duplRows.sort_values('NumberNA', inplace=True)\n",
    "            # recomibine into final frame\n",
    "            data = pd.concat([data[~bDuplicate], duplRows[duplRows.index.duplicated(keep='first')]])\n",
    "    \n",
    "    elif prefix == 'pagamenti':\n",
    "        # pagamenti has many rows with no money amount. Drop them.\n",
    "        frames = list(map(lambda f: pd.read_csv(f, sep=';', index_col=False), fileList))\n",
    "        data = pd.concat(frames, axis=0)\n",
    "        \n",
    "        # drop duplicates excluding index\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        data = data[~np.all(data.select_dtypes(float) == 0, axis=1)]\n",
    "         \n",
    "    else:\n",
    "        # infer types for other datasets (temporary)\n",
    "        frames = list(map(lambda f: pd.read_csv(f, sep=';', index_col=False, na_values=[' ', '  '], \n",
    "                                                dtype={'COD_COMUNE_SEDE_SOGG':float}), fileList))\n",
    "        data = pd.concat(frames, axis=0)\n",
    "        \n",
    "        # drop duplicates excluding index\n",
    "        data.drop_duplicates(inplace=True)\n",
    "    \n",
    "    data.drop(columns = columnsToDrop[prefix], inplace=True)\n",
    "    print('Imported %s' % prefix)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load datasets\n",
    "progetti = load_and_stack_data('progetti')\n",
    "luoghi = load_and_stack_data('localizzazioni')\n",
    "soggetti = load_and_stack_data('soggetti')\n",
    "\n",
    "# convert Comune fields:\n",
    "# soggetti\n",
    "soggetti.loc[soggetti['COD_COMUNE_SEDE_SOGG'].isna(), 'COD_COMUNE_SEDE_SOGG'] = -1\n",
    "soggetti['COD_COMUNE_SEDE_SOGG'] = soggetti['COD_COMUNE_SEDE_SOGG'].astype(int) \n",
    "# luoghi\n",
    "padZerosShort = np.vectorize(lambda x: str(x).rjust(3, '0'))\n",
    "luoghi['COD_COMUNE_LUOGO'] = (luoghi.COD_REGIONE.astype('str') + \n",
    "                              padZerosShort(luoghi.COD_PROVINCIA) + padZerosShort(luoghi.COD_COMUNE)).astype(int)\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caricamento anagrafica comuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comuniAnagrafica = pd.read_csv('../ElencoComuniAttuali_20170918.csv', sep=';')\n",
    "comuniAnagrafica.set_index('Codice Istat', inplace=True)\n",
    "comuniAnagrafica = comuniAnagrafica[~comuniAnagrafica.index.isnull()]\n",
    "#print(sum(comuniAnagrafica.index.isnull()))\n",
    "assert not any(comuniAnagrafica.index.duplicated()), 'Duplicate Istat codes'\n",
    "\n",
    "convTable = pd.read_csv('../provToReg.csv', index_col='Sigla automobilistica', dtype='str')\n",
    "\n",
    "comuniAnagrafica = comuniAnagrafica.join(convTable, on='Sigla Provincia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formattedValues = comuniAnagrafica.index.values.astype('int')\n",
    "padZeros = np.vectorize(lambda x: str(x).rjust(6, '0'))\n",
    "comuniAnagrafica['Codice Istat Lungo'] = (comuniAnagrafica['Codice regione'] + padZeros(formattedValues)).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gestione progetti con piu' luoghi / soggetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeroSoggetti = soggetti[soggetti.SOGG_COD_RUOLO == 2].groupby('COD_LOCALE_PROGETTO').size()\n",
    "bProgettoMoltiSoggetti = progetti.index.isin(numeroSoggetti.index[numeroSoggetti > 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeroLuoghi = luoghi[luoghi.OC_FLAG_CAP_PROG==1].groupby('COD_LOCALE_PROGETTO').size()\n",
    "\n",
    "bProgettoMoltiLuoghi = progetti.index.isin(numeroLuoghi.index[numeroLuoghi > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bProgettoNonMappabile = bProgettoMoltiLuoghi | bProgettoMoltiSoggetti\n",
    "\n",
    "print('---CONSIDERATI PROGETTI con solo un luogo e un soggetto attuatore. Esclusi EUR %.2f' %\n",
    "      sum(progetti.TOT_PAGAMENTI[bProgettoMoltiLuoghi | bProgettoMoltiSoggetti]))\n",
    "progettiMap = progetti[~bProgettoNonMappabile]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join: pagamenti + (progetti con altre variabili uniche, soggetti attuatori e luoghi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: JOIN soggetti - progettiMap index\n",
    "datiUniti = progettiMap[['CUP','TOT_PAGAMENTI']].join(soggetti[soggetti.SOGG_COD_RUOLO == 2].set_index('COD_LOCALE_PROGETTO'))\n",
    "firstJoinTotPagamenti = datiUniti.TOT_PAGAMENTI.sum()\n",
    "\n",
    "bMatch = datiUniti['COD_COMUNE_SEDE_SOGG'].isin(comuniAnagrafica['Codice Istat Lungo'].values)\n",
    "bMatch = bMatch | (datiUniti['COD_COMUNE_SEDE_SOGG'] == -1)\n",
    "\n",
    "print('---CONSIDERATI PROGETTI con comune soggetto che corrisponde ad anagrafica. Restano scollegati EUR %.6g' %\n",
    "      datiUniti[~bMatch]['TOT_PAGAMENTI'].sum())\n",
    "\n",
    "del soggetti\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2: JOIN previous union - luoghi\n",
    "datiUniti = datiUniti.join(luoghi[luoghi.OC_FLAG_CAP_PROG==1].set_index('COD_LOCALE_PROGETTO'))\n",
    "assert datiUniti.TOT_PAGAMENTI.sum() == firstJoinTotPagamenti, 'Inconsistent join'\n",
    "\n",
    "bMatchLuogo = datiUniti['COD_COMUNE_LUOGO'].isin(comuniAnagrafica['Codice Istat Lungo'].values)\n",
    "\n",
    "print('---CONSIDERATI PROGETTI con assegnazione a livello comunale che corrisponde ad anagrafica. Restano scollegati EUR %.6g' %\n",
    "      datiUniti[~bMatchLuogo]['TOT_PAGAMENTI'].sum())\n",
    "\n",
    "del luoghi\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3: JOIN pagamenti-progetti // fill pagamenti data with the above info\n",
    "\n",
    "bTriggerJoinPagamenti = False\n",
    "bTriggerJoinPagamenti = True\n",
    "if bTriggerJoinPagamenti:\n",
    "    # check pagamenti sums\n",
    "    pagamenti = load_and_stack_data('pagamenti')\n",
    "    origSum = pagamenti['TOT_PAGAMENTI'].sum() # ok, around 60B\n",
    "\n",
    "    # do the join\n",
    "    datiUnitiPagamenti = datiUniti.join(pagamenti.set_index('COD_LOCALE_PROGETTO'),  lsuffix='_summary')\n",
    "    del pagamenti\n",
    "    gc.collect()\n",
    "\n",
    "    # Finally recheck the sums!\n",
    "    assert 0 == datiUnitiPagamenti.TOT_PAGAMENTI.sum().round() - firstJoinTotPagamenti.round(), 'Bad pagamenti data'\n",
    "    datiUnitiPagamenti.to_csv('../pac_opencoesione/pagamentiSoggettiLuoghi.csv')\n",
    "else:\n",
    "    datiUniti.to_csv('../pac_opencoesione/SoggettiELuoghi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summary on beneficiary types\n",
    "datiUniti.groupby('COD_COMUNE_SEDE_SOGG')['COD_COMUNE_LUOGO'].nunique().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
